import os
import re
import logging
from datetime import datetime
from io import BytesIO
from pydub import AudioSegment
from flask import Flask, request, jsonify
from elevenlabs import ElevenLabs, VoiceSettings

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TextToPodcastMiddleware:
    """
    Flask middleware for converting podcast scripts to audio using ElevenLabs TTS API
    """
    
    def __init__(self):
        # ElevenLabs API configuration - replace with your actual credentials
        self.api_key = "YOUR_API_KEY"
        self.client = ElevenLabs(api_key=self.api_key)
        
        # Voice mapping for different speakers - replace with your actual voice IDs
        self.voice_mapping = {
            "host": "VOICE_ID_1",  # Riley Thompson
            "elena": "VOICE_ID_2",  # Dr. Elena Garcia
            "james": "VOICE_ID_3",  # Prof. James Liu
            "maria": "VOICE_ID_4",  # Dr. Maria Nguyen
            "alex": "VOICE_ID_5"   # Alex Johnson
        }
        
        # Default voice settings for consistent quality
        self.voice_settings = VoiceSettings(
            stability=0.75,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True
        )
        
        # Ensure audio directory exists
        self.audio_dir = "audio"
        self._create_audio_directory()
    
    def _create_audio_directory(self):
        """Create audio directory if it doesn't exist"""
        try:
            if not os.path.exists(self.audio_dir):
                os.makedirs(self.audio_dir)
                logger.info(f"Created audio directory: {self.audio_dir}")
        except Exception as e:
            logger.error(f"Failed to create audio directory: {str(e)}")
            raise
    
    def _parse_podcast_script(self, text):
        """
        Parse podcast script and extract speaker segments
        Returns list of tuples: (speaker_key, text_content)
        """
        segments = []
        
        try:
            # Split text into lines and process each line
            lines = text.strip().split('\n')
            current_speaker = None
            current_text = []
            
            for line in lines.strip():
                line = line.strip()
                if not line:
                    continue
                
                # Check for speaker patterns (bold text with speaker names)
                speaker_match = re.match(r'\*\*([^*]+)\*\*:?\s*(.*)', line)
                if speaker_match:
                    # Save previous speaker's content
                    if current_speaker and current_text:
                        segments.append((current_speaker, ' '.join(current_text)))
                        current_text = []
                    
                    # Identify new speaker
                    speaker_full = speaker_match.group(1).lower()
                    remaining_text = speaker_match.group(2)
                    
                    # Map speaker names to voice keys
                    if 'riley' in speaker_full or 'host' in speaker_full:
                        current_speaker = 'host'
                    elif 'elena' in speaker_full:
                        current_speaker = 'elena'
                    elif 'james' in speaker_full:
                        current_speaker = 'james'
                    elif 'maria' in speaker_full:
                        current_speaker = 'maria'
                    elif 'alex' in speaker_full:
                        current_speaker = 'alex'
                    else:
                        current_speaker = 'host'  # Default to host voice
                    
                    # Add remaining text from speaker line
                    if remaining_text:
                        current_text.append(remaining_text)
                
                # Check for section headers (ignore them for speech)
                elif line.startswith('##') or line.startswith('---'):
                    continue
                
                # Regular text continuation
                else:
                    if current_speaker:
                        current_text.append(line)
            
            # Don't forget the last speaker's content
            if current_speaker and current_text:
                segments.append((current_speaker, ' '.join(current_text)))
            
            logger.info(f"Parsed {len(segments)} speaker segments")
            return segments
            
        except Exception as e:
            logger.error(f"Error parsing podcast script: {str(e)}")
            raise
    
    def _generate_speech_segment(self, text, voice_id):
        """
        Generate speech for a single text segment using specified voice
        Returns audio bytes
        """
        try:
            # Generate speech using ElevenLabs API
            audio_generator = self.client.generate(
                text=text,
                voice=voice_id,
                voice_settings=self.voice_settings,
                model="eleven_multilingual_v2"  # Use multilingual model for better quality
            )
            
            # Convert generator to bytes
            audio_bytes = b''.join(audio_generator)
            logger.info(f"Generated {len(audio_bytes)} bytes of audio")
            return audio_bytes
            
        except Exception as e:
            logger.error(f"Error generating speech with voice {voice_id}: {str(e)}")
            raise
    
    def _combine_audio_segments(self, audio_segments):
        """
        Combine multiple audio segments into a single audio file
        Returns combined AudioSegment
        """
        try:
            combined_audio = AudioSegment.empty()
            
            for i, audio_bytes in enumerate(audio_segments):
                # Convert bytes to AudioSegment
                audio_segment = AudioSegment.from_mp3(BytesIO(audio_bytes))
                
                # Add a brief pause between speakers (500ms)
                if i > 0:
                    pause = AudioSegment.silent(duration=500)
                    combined_audio += pause
                
                combined_audio += audio_segment
                logger.info(f"Added audio segment {i+1}/{len(audio_segments)}")
            
            return combined_audio
            
        except Exception as e:
            logger.error(f"Error combining audio segments: {str(e)}")
            raise
    
    def generate_podcast_audio(self, text, filename=None):
        """
        Main method to convert podcast script text to audio file
        """
        try:
            # Generate filename if not provided
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"podcast_{timestamp}.mp3"
            
            # Ensure filename has .mp3 extension
            if not filename.endswith('.mp3'):
                filename += '.mp3'
            
            logger.info(f"Starting podcast generation: {filename}")
            
            # Parse the script into speaker segments
            segments = self._parse_podcast_script(text)
            
            if not segments:
                raise ValueError("No speaker segments found in the provided text")
            
            # Generate audio for each segment
            audio_segments = []
            for speaker_key, text_content in segments:
                voice_id = self.voice_mapping.get(speaker_key, self.voice_mapping['host'])
                logger.info(f"Generating audio for {speaker_key} ({len(text_content)} chars)")
                
                audio_bytes = self._generate_speech_segment(text_content, voice_id)
                audio_segments.append(audio_bytes)
            
            # Combine all audio segments
            logger.info("Combining audio segments...")
            combined_audio = self._combine_audio_segments(audio_segments)
            
            # Save the final audio file
            output_path = os.path.join(self.audio_dir, filename)
            combined_audio.export(output_path, format="mp3", bitrate="192k")
            
            logger.info(f"Podcast audio saved successfully: {output_path}")
            
            return {
                "success": True,
                "filename": filename,
                "path": output_path,
                "duration": len(combined_audio) / 1000.0,  # Duration in seconds
                "segments_count": len(segments)
            }
            
        except Exception as e:
            logger.error(f"Error generating podcast audio: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

# Flask application setup
app = Flask(__name__)
tts_middleware = TextToPodcastMiddleware()

@app.route('/generate-podcast', methods=['POST'])
def generate_podcast():
    """
    Flask endpoint to generate podcast audio from text
    Expects JSON payload with 'text' field and optional 'filename' field
    """
    try:
        # Get JSON data from request
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({
                "success": False,
                "error": "Missing 'text' field in request body"
            }), 400
        
        text = data['text']
        filename = data.get('filename', None)
        
        # Validate text input
        if not text.strip():
            return jsonify({
                "success": False,
                "error": "Text field cannot be empty"
            }), 400
        
        # Generate podcast audio
        result = tts_middleware.generate_podcast_audio(text, filename)
        
        if result['success']:
            return jsonify(result), 200
        else:
            return jsonify(result), 500
            
    except Exception as e:
        logger.error(f"Error in generate_podcast endpoint: {str(e)}")
        return jsonify({
            "success": False,
            "error": "Internal server error occurred"
        }), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "service": "text-to-podcast",
        "timestamp": datetime.now().isoformat()
    })

# Middleware function for existing Flask applications
def add_text_to_podcast_middleware(existing_app):
    """
    Function to add text-to-podcast functionality to existing Flask applications
    Usage: add_text_to_podcast_middleware(your_app)
    """
    global tts_middleware
    
    # Add the generate-podcast route to existing app
    @existing_app.route('/generate-podcast', methods=['POST'])
    def generate_podcast_middleware():
        return generate_podcast()
    
    # Add health check route
    @existing_app.route('/podcast-health', methods=['GET'])
    def podcast_health_middleware():
        return health_check()
    
    logger.info("Text-to-podcast middleware added to existing Flask application")

if __name__ == '__main__':
    # Run standalone Flask app for testing
    app.run(debug=True, host='0.0.0.0', port=5000)